{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import where\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "X, y = make_blobs(n_samples=5000, centers=2, random_state=1)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "\n",
    "for i in range(10):\n",
    "    print(X[i], y[i])\n",
    "\n",
    "for label, _ in counter.items():\n",
    "    row_ix = where(y == label)[0]\n",
    "    pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import where\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot\n",
    "\n",
    "X, y = make_blobs(n_samples=1000, centers=4, random_state=1)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "\n",
    "for i in range(10):\n",
    "  print(X[i], y[i])\n",
    "\n",
    "for label, _ in counter.items():\n",
    "  row_ix = where(y == label)[0]\n",
    "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Label Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "\n",
    "X, y = make_multilabel_classification(n_samples=1000, n_features=3, \n",
    "                                      n_classes=4, n_labels=4, random_state=1)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import where\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from matplotlib import pyplot\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_informative=2, \n",
    "                           n_redundant=0, n_classes=2, n_clusters_per_class=1, \n",
    "                           weights=[0.99,0.01], random_state=1)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "\n",
    "for i in range(10):\n",
    "  print(X[i], y[i])\n",
    "\n",
    "for label, _ in counter.items():\n",
    "  row_ix = where(y == label)[0]\n",
    "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Let's start with importing necessary libraries\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"diabetes.csv\") # Reading the Data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how data is distributed for every column\n",
    "plt.figure(figsize=(20,25), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in data:\n",
    "    if plotnumber<=9 :     # as there are 9 columns in the data\n",
    "        ax = plt.subplot(3,3,plotnumber)\n",
    "        sns.distplot(data[column])\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "        #plt.ylabel('Salary',fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing zero values with the mean of the column\n",
    "data['BMI'] = data['BMI'].replace(0,data['BMI'].mean())\n",
    "data['BloodPressure'] = data['BloodPressure'].replace(0,data['BloodPressure'].mean())\n",
    "data['Glucose'] = data['Glucose'].replace(0,data['Glucose'].mean())\n",
    "data['Insulin'] = data['Insulin'].replace(0,data['Insulin'].mean())\n",
    "data['SkinThickness'] = data['SkinThickness'].replace(0,data['SkinThickness'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how data is distributed for every column\n",
    "plt.figure(figsize=(20,25), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in data:\n",
    "    if plotnumber<=9 :\n",
    "        ax = plt.subplot(3,3,plotnumber)\n",
    "        sns.distplot(data[column])\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "        #plt.ylabel('Salary',fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.boxplot(data=data, width= 0.5,ax=ax,  fliersize=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = data['Pregnancies'].quantile(0.98)\n",
    "# we are removing the top 2% data from the Pregnancies column\n",
    "data_cleaned = data[data['Pregnancies']<q]\n",
    "q = data_cleaned['BMI'].quantile(0.99)\n",
    "# we are removing the top 1% data from the BMI column\n",
    "data_cleaned  = data_cleaned[data_cleaned['BMI']<q]\n",
    "q = data_cleaned['SkinThickness'].quantile(0.99)\n",
    "# we are removing the top 1% data from the SkinThickness column\n",
    "data_cleaned  = data_cleaned[data_cleaned['SkinThickness']<q]\n",
    "q = data_cleaned['Insulin'].quantile(0.95)\n",
    "# we are removing the top 5% data from the Insulin column\n",
    "data_cleaned  = data_cleaned[data_cleaned['Insulin']<q]\n",
    "q = data_cleaned['DiabetesPedigreeFunction'].quantile(0.99)\n",
    "# we are removing the top 1% data from the DiabetesPedigreeFunction column\n",
    "data_cleaned  = data_cleaned[data_cleaned['DiabetesPedigreeFunction']<q]\n",
    "q = data_cleaned['Age'].quantile(0.99)\n",
    "# we are removing the top 1% data from the Age column\n",
    "data_cleaned  = data_cleaned[data_cleaned['Age']<q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how data is distributed for every column\n",
    "plt.figure(figsize=(20,25), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in data_cleaned:\n",
    "    if plotnumber<=9 :\n",
    "        ax = plt.subplot(3,3,plotnumber)\n",
    "        sns.distplot(data_cleaned[column])\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "        #plt.ylabel('Salary',fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns = ['Outcome'])\n",
    "y = data['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how data is distributed for every column\n",
    "plt.figure(figsize=(20,25), facecolor='white')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in X:\n",
    "    if plotnumber<=9 :\n",
    "        ax = plt.subplot(3,3,plotnumber)\n",
    "        sns.stripplot(y,X[column])\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "X_scaled = scalar.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"vif\"] = [variance_inflation_factor(X_scaled,i) for i in range(X_scaled.shape[1])]\n",
    "vif[\"Features\"] = X.columns\n",
    "\n",
    "#let's check the values\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X_scaled,y, test_size= 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's fit the data into kNN model and see how well it performs:\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy score is : \", accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { 'algorithm' : ['ball_tree', 'kd_tree', 'brute'],\n",
    "               'leaf_size' : [18,20,25,27,30,32,34],\n",
    "               'n_neighbors' : [3,5,7,9,10,11,12,13]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch = GridSearchCV(knn, param_grid,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see the  best parameters according to gridsearch\n",
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the best parameters in our k-NN algorithm and check if accuracy is increasing.\n",
    "knn = KNeighborsClassifier(algorithm = 'ball_tree', leaf_size =18, n_neighbors =13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-fold cross validation \n",
    "kfold = KFold(n_splits=12,random_state= 42, shuffle=True)\n",
    "kfold.get_n_splits(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "knn = KNeighborsClassifier(algorithm = 'ball_tree', leaf_size =18, n_neighbors =11)\n",
    "cnt =0\n",
    "count=[]\n",
    "train_score =[]\n",
    "test_score = []\n",
    "\n",
    "for train_index,test_index in kfold.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index] # our scaled data is an array so it can work on x[value]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index] # y is a dataframe so we have to use \"iloc\" to retreive data\n",
    "    knn.fit(X_train,y_train)\n",
    "    train_score_ = knn.score(X_train,y_train)\n",
    "    test_score_ =  knn.score(X_test,y_test)\n",
    "    cnt+=1\n",
    "    count.append(cnt)\n",
    "    train_score.append(train_score_)\n",
    "    test_score.append(test_score_)\n",
    "    \n",
    "    print(\"for k = \", cnt)\n",
    "    print(\"train_score is :  \", train_score_, \"and test score is :  \", test_score_)\n",
    "print(\"************************************************\")\n",
    "print(\"************************************************\")\n",
    "print(\"Average train score is :  \", mean(train_score))\n",
    "print(\"Average test score is :  \", mean(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the test_accuracy with the value of k in k-fold\n",
    "\n",
    "plt.plot(count,test_score)\n",
    "plt.xlabel('Value of K for k-fold')\n",
    "plt.ylabel('test accuracy')\n",
    "plt.xticks(np.arange(0, 12, 1)) \n",
    "plt.yticks(np.arange(0.65, 1, 0.05)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-fold cross validation \n",
    "kfold = KFold(n_splits=12,random_state= 42, shuffle=True)\n",
    "kfold.get_n_splits(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "knn = KNeighborsClassifier(algorithm = 'ball_tree', \n",
    "                           leaf_size =18, n_neighbors =11)\n",
    "cnt =0\n",
    "count=[]\n",
    "train_score =[]\n",
    "test_score = []\n",
    "\n",
    "for train_index,test_index in kfold.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index] # our scaled data is an array so it can work on x[value]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index] # y is a dataframe so we have to use \"iloc\" to retreive data\n",
    "    knn.fit(X_train,y_train)\n",
    "    train_score_ = knn.score(X_train,y_train)\n",
    "    test_score_ =  knn.score(X_test,y_test)\n",
    "    cnt+=1\n",
    "    count.append(cnt)\n",
    "    train_score.append(train_score_)\n",
    "    test_score.append(test_score_)\n",
    "    \n",
    "    print(\"for k = \", cnt)\n",
    "    print(\"train_score is :  \", train_score_, \"and test score is :  \", test_score_)\n",
    "print(\"************************************************\")\n",
    "print(\"************************************************\")\n",
    "print(\"Average train score is :  \", mean(train_score))\n",
    "print(\"Average test score is :  \", mean(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's plot the test_accuracy with the value of k in k-fold\n",
    "\n",
    "plt.plot(count,test_score)\n",
    "plt.xlabel('Value of K for k-fold')\n",
    "plt.ylabel('test accuracy')\n",
    "plt.xticks(np.arange(0, 12, 1)) \n",
    "plt.yticks(np.arange(0.65, 1, 0.05)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
